{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('dataset_connected_NYC.mat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendship_new = mat['friendship_new']\n",
    "friendship_old = mat['friendship_old']#new_friendship_old\n",
    "selected_checkins = mat['selected_checkins'] #new_checkins\n",
    "selected_users_IDs = mat['selected_users_IDs'] #new_users_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      1      46 3259566     120]\n",
      " [      1      68      62      44]\n",
      " [      1      13 5032552     230]\n",
      " [      4      37   15947     150]\n",
      " [      4      39 1748219      72]\n",
      " [      4      69 2260369     248]\n",
      " [      1      95     372      48]\n",
      " [      4     115   12743     243]\n",
      " [      4     120 2190699      61]\n",
      " [      4     134   67999     283]\n",
      " [      3     147   13320      44]\n",
      " [      1     160    7620     168]\n",
      " [      1      22   12743     243]\n",
      " [      9      57   18032     307]\n",
      " [      2      65 5323788      72]\n",
      " [      1      67    9828      72]\n",
      " [      2      70   12818     397]\n",
      " [      1      70     155      48]\n",
      " [      2      83 5793549      72]\n",
      " [      4     106   97131      70]\n",
      " [      1     110   10416       8]\n",
      " [      1     115    6344      80]\n",
      " [      4     133     555     307]\n",
      " [     10     139 1578583     380]\n",
      " [      1      47 5575535     163]\n",
      " [      1      95    1455      44]\n",
      " [      1     117 2475486      59]\n",
      " [      1     118 6193087     120]\n",
      " [      1     119   10402      25]\n",
      " [      1     121  393767      66]\n",
      " [      1     122 2475486      59]\n",
      " [      1     140      76      44]\n",
      " [      1      42   48317     259]\n",
      " [      1      46      26      44]\n",
      " [      1      58   14006     259]\n",
      " [      1      92     552      43]\n",
      " [      4      93      22      25]\n",
      " [      1      93      62      44]\n",
      " [      1     109   14396      70]\n",
      " [      1     141 2872330     129]\n",
      " [      1     145    3737     276]\n",
      " [      1     162    1765      46]\n",
      " [      1      10   14006     259]\n",
      " [      4      10   11068      68]\n",
      " [      4      19 1026175     157]\n",
      " [      1      21   12576      44]\n",
      " [      4      22     692      44]\n",
      " [      4      35    1331     109]\n",
      " [      1      48     372      48]\n",
      " [      1     113  270678     279]\n",
      " [      1     112    7607     283]\n",
      " [      1      45    3765      68]\n",
      " [      1      46 4057879     238]\n",
      " [      1     156    1774     141]\n",
      " [      8      19 1484126     150]\n",
      " [      1      34 4834770     151]\n",
      " [      8      68    3851     101]\n",
      " [      1      72 5323788      72]\n",
      " [      1      82 5323788      72]\n",
      " [      1      91    8876      70]\n",
      " [      1     114 5323788      72]\n",
      " [      1      32   16928     264]\n",
      " [      1      44     166      54]\n",
      " [      1      58   16421      49]\n",
      " [      2      63    3949      54]\n",
      " [      1      70 4748754      33]\n",
      " [      1      71    3731     150]\n",
      " [      4      46    1267      44]\n",
      " [      4      61    9113     120]\n",
      " [      1     108     552      43]\n",
      " [      1     112   20140     307]\n",
      " [      2      45    1052     297]\n",
      " [      1      58  762363     120]\n",
      " [      1      93    3949      54]\n",
      " [      1     114 5323788      72]\n",
      " [      1     160 6068095      44]\n",
      " [      1     163   16057     168]\n",
      " [      3     118   12014     230]\n",
      " [      3     119   12992      46]\n",
      " [      3     162    9703     148]\n",
      " [      1     168    7600      57]\n",
      " [      1      10 5228452     259]\n",
      " [      3      94    5727     167]\n",
      " [      3     119   12992      46]\n",
      " [      1      35    1509     120]\n",
      " [      3      88   54773     140]\n",
      " [      1      89 5323788      72]\n",
      " [      1      93 1010050     263]\n",
      " [      3     118   17280     167]\n",
      " [      1     163   16800     293]\n",
      " [      1     164 4175391     243]\n",
      " [      1     111    9298     298]\n",
      " [      3     141    7607     283]\n",
      " [      1      95 2088056     127]\n",
      " [      1     105    1459     120]\n",
      " [      3     118 2008806      46]\n",
      " [      2      21    7664      57]\n",
      " [      1      38 5323788      72]\n",
      " [      3      44   24342      70]\n",
      " [      1      44 5760759      57]\n",
      " [      1      46   12485     257]\n",
      " [      1      48   19447      44]\n",
      " [      3      68   24197      72]\n",
      " [      1      69    7467     127]\n",
      " [      3      92   21648      17]\n",
      " [      3      93   17904      17]\n",
      " [      2      96   13975     276]\n",
      " [      2     141    7664      57]\n",
      " [      2     166    7664      57]\n",
      " [      2      41    6228     141]\n",
      " [      2      45    7524     167]\n",
      " [      1      35 5323788      72]\n",
      " [      1      46     372      48]\n",
      " [      1     135   67999     283]\n",
      " [      1     159   18450     253]\n",
      " [      1     165 2105411      27]\n",
      " [      9      91 3412872     150]\n",
      " [      3      92   14396      70]\n",
      " [      1     117     372      48]\n",
      " [      1     134    5489     122]\n",
      " [      3      43 1051145     157]\n",
      " [      3     165 7653422     299]\n",
      " [      1     115    7607     283]\n",
      " [      2      19    7607     283]\n",
      " [      3      22    7607     283]\n",
      " [      1      65   18450     253]\n",
      " [      1      82   93320     259]\n",
      " [      1     106   14006     259]\n",
      " [      1     122   49351      57]\n",
      " [      1      24    1267      44]\n",
      " [      1      34    7607     283]\n",
      " [      1     140    7607     283]\n",
      " [      1       9 7203092     259]\n",
      " [      1      44  537734     190]\n",
      " [      1      58   14006     259]\n",
      " [      1      91   11386     189]\n",
      " [      1     106   14006     259]\n",
      " [      1     110    9298     298]\n",
      " [      1     113 9003189     338]\n",
      " [      3     141 1477065     111]\n",
      " [      1     105    7607     283]\n",
      " [      4     142  414684      33]\n",
      " [      4      22 9165631     140]\n",
      " [      1     117    7607     283]\n",
      " [      1     137 5323788      72]\n",
      " [      1       9 7203092     259]\n",
      " [      1      44   27194     211]\n",
      " [      1      57 7203092     259]\n",
      " [      1      94   12576      44]\n",
      " [      3     110  873977     123]\n",
      " [      1     110 3270168      33]\n",
      " [      3     132    8996     228]\n",
      " [      3     134    5988     182]\n",
      " [      1      13 3270168      33]\n",
      " [      1      62 3270168      33]\n",
      " [      3      88   47409     368]\n",
      " [      6      91 3597860     150]\n",
      " [      6     109    1186     397]\n",
      " [      3     110   15840     230]\n",
      " [      6     131   33576     158]\n",
      " [      6     159   16688     168]\n",
      " [      1     106   14006     259]\n",
      " [      3     111    1714     259]\n",
      " [      3     154  811385     281]\n",
      " [      3     154   21028     279]\n",
      " [      1     161 6068095      44]\n",
      " [      1      70     243      48]\n",
      " [      1      82 2122340     225]\n",
      " [      1      92     166      54]\n",
      " [      1      44    3949      54]\n",
      " [      1      47   27194     211]\n",
      " [      1     120   18450     253]\n",
      " [      1     120     155      48]\n",
      " [      3      14     689     111]\n",
      " [      5      13    5522     150]\n",
      " [      5      16   14608      67]\n",
      " [      5      44  215786     380]\n",
      " [      5      59    7957     113]\n",
      " [      5      69    9059     239]\n",
      " [      5      70 1766860     298]\n",
      " [      3     161    7607     283]\n",
      " [      1     107   53836     307]\n",
      " [      1     140    1720      44]\n",
      " [      1     144 2008806      46]\n",
      " [      3     159   91700      44]\n",
      " [      5     162    7607     283]\n",
      " [      1      63 3270168      33]\n",
      " [      1     142    1022     241]\n",
      " [      1     163 4416985      33]\n",
      " [      3      67 5323788      72]\n",
      " [      1      68 5793549      72]\n",
      " [      1     117 5323788      72]\n",
      " [      1     117  192333      49]\n",
      " [      1     136     228      27]\n",
      " [      1     157 2105411      27]\n",
      " [      3     120   95909     125]\n",
      " [      3     121    6567     276]\n",
      " [      1     137 1830754     190]\n",
      " [      3     143   28455     245]\n",
      " [      3      81    7607     283]\n",
      " [      3     159    7607     283]\n",
      " [      1     163   12344     111]\n",
      " [      3      93   66979     112]\n",
      " [      1      96    5607      25]\n",
      " [      1     107   14006     259]\n",
      " [      1     132   13003     182]\n",
      " [      1     165 9880761      25]\n",
      " [      1      10   14006     259]\n",
      " [      1      34   14006     259]\n",
      " [      1     144 9636347      44]\n",
      " [      1     161    7809     253]\n",
      " [      1     112    7607     283]\n",
      " [      1      35   14006     259]\n",
      " [      7      38  157697     148]\n",
      " [      7      41    1257      54]\n",
      " [      1      48    1088     153]\n",
      " [      1      48    1088     153]\n",
      " [      7     140   12334     166]\n",
      " [      3      15    6228     141]\n",
      " [      1      62    9298     298]\n",
      " [      1     164 4175391     243]\n",
      " [      2      44 5323788      72]\n",
      " [      2      45 4057879     238]\n",
      " [      1      45 4057879     238]\n",
      " [      1     162 4175391     243]\n",
      " [      3      35 3524433     259]\n",
      " [      3      84    7607     283]\n",
      " [      1     112    7607     283]\n",
      " [      3     165    7911     166]\n",
      " [      1      62 3270168      33]\n",
      " [      1      21    1643      54]\n",
      " [      1      19    1281     243]\n",
      " [      1     139    1630      44]\n",
      " [      3     112 5288851     150]\n",
      " [      1      69 4175391     243]\n",
      " [      3      25    7607     283]\n",
      " [      3      43 5861545     157]\n",
      " [      3      61 3524433     259]\n",
      " [      3     110   67999     283]\n",
      " [      1      43    9329     259]\n",
      " [      1      43  537734     190]\n",
      " [      1      45 9880761      25]\n",
      " [      1      58 2122340     225]\n",
      " [      1      94 5844430     230]\n",
      " [      1      82   14006     151]\n",
      " [      1     107   14006     151]]\n",
      "[[ 1  2]\n",
      " [ 1  9]\n",
      " [ 1  5]\n",
      " [ 1  2]\n",
      " [ 1 10]\n",
      " [ 1 10]\n",
      " [ 1  8]\n",
      " [ 1  8]\n",
      " [ 1  2]\n",
      " [ 1  5]\n",
      " [ 1  2]\n",
      " [ 1  8]\n",
      " [ 1  7]\n",
      " [ 1  9]\n",
      " [ 1  9]\n",
      " [ 1  7]\n",
      " [ 2  5]\n",
      " [ 2  2]\n",
      " [ 2  2]\n",
      " [ 2 10]\n",
      " [ 2  9]\n",
      " [ 2  5]\n",
      " [ 2  2]\n",
      " [ 2  2]\n",
      " [ 3  3]\n",
      " [ 3  1]\n",
      " [ 3  2]\n",
      " [ 3  4]\n",
      " [ 4  3]\n",
      " [ 4  5]\n",
      " [ 4  6]\n",
      " [ 4  7]\n",
      " [ 4  3]\n",
      " [ 4  3]\n",
      " [ 4 10]\n",
      " [ 4  8]\n",
      " [ 4  4]\n",
      " [ 4  4]\n",
      " [ 4  7]\n",
      " [ 4  4]\n",
      " [ 4  4]\n",
      " [ 4  3]\n",
      " [ 4  6]\n",
      " [ 4  5]\n",
      " [ 4  5]\n",
      " [ 4  2]\n",
      " [ 4 10]\n",
      " [ 4  4]\n",
      " [ 4  1]\n",
      " [ 4  9]\n",
      " [ 4  9]\n",
      " [ 4  5]\n",
      " [ 4  2]\n",
      " [ 4  2]\n",
      " [ 5  6]\n",
      " [ 5  5]\n",
      " [ 6  2]\n",
      " [ 6  4]\n",
      " [ 7 10]\n",
      " [ 7  5]\n",
      " [ 7  4]\n",
      " [ 7  3]\n",
      " [ 7  7]\n",
      " [ 7  4]\n",
      " [ 7  1]\n",
      " [ 7 10]\n",
      " [ 7  8]\n",
      " [ 7  4]\n",
      " [ 7  2]\n",
      " [ 7 10]\n",
      " [ 7  9]\n",
      " [ 7 10]\n",
      " [ 7 10]\n",
      " [ 7  6]\n",
      " [ 7  2]\n",
      " [ 7  4]\n",
      " [ 8  1]\n",
      " [ 8  3]\n",
      " [ 8  2]\n",
      " [ 8  1]\n",
      " [ 8  2]\n",
      " [ 8  2]\n",
      " [ 8  7]\n",
      " [ 8  3]\n",
      " [ 9  4]\n",
      " [ 9  4]\n",
      " [10  8]]\n",
      "[[ 19]\n",
      " [ 54]\n",
      " [ 58]\n",
      " [ 78]\n",
      " [198]\n",
      " [275]\n",
      " [295]\n",
      " [319]\n",
      " [448]\n",
      " [510]]\n"
     ]
    }
   ],
   "source": [
    "#do not run this if entire dataset is required\n",
    "import random\n",
    "\n",
    "qty = 10;\n",
    "\n",
    "new_users_IDs = selected_users_IDs[:qty];\n",
    "\n",
    "new_friendship_old = []\n",
    "for i in range(np.size(friendship_old,0)):\n",
    "    if ((friendship_old[i,0]<=qty) or (friendship_old[i,1]<=qty)):\n",
    "        new_friendship_old.append(friendship_old[i,:])\n",
    "        \n",
    "new_friendship_old = np.array(new_friendship_old)\n",
    "\n",
    "\n",
    "#make sure all qty user ids are accounted for atleast\n",
    "#once in the friendship matrix\n",
    "#found = np.zeros((qty,))\n",
    "#for i in range(qty):\n",
    "#    found[i] = i in new_friendship_old\n",
    "#temp = np.where(found == 0)[0]; #ensure that all users are accounted for atleast once\n",
    "\n",
    "\n",
    "for i in range(np.size(new_friendship_old,0)):\n",
    "    if new_friendship_old[i,0]>qty:\n",
    "        new_friendship_old[i,0]=random.randint(1,qty)\n",
    "    elif new_friendship_old[i,1]>qty:\n",
    "        new_friendship_old[i,1]=random.randint(1,qty)\n",
    "\n",
    "new_checkins = []\n",
    "for i in range(np.size(selected_checkins,0)):\n",
    "    if selected_checkins[i,0]<=qty:\n",
    "        new_checkins.append(selected_checkins[i,:])\n",
    "\n",
    "#assigning original variables\n",
    "\n",
    "selected_checkins = np.array(new_checkins)\n",
    "friendship_old = np.array(new_friendship_old)\n",
    "selected_users_IDs = new_users_IDs\n",
    "\n",
    "#verify\n",
    "\n",
    "print(selected_checkins)\n",
    "print(friendship_old)\n",
    "print(selected_users_IDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. rebuild node index\n",
    "offset1 = max(selected_checkins[:,0]);\n",
    "dumy, dumy, n = np.unique(selected_checkins[:,1],return_index=True,return_inverse=True, axis=0)\n",
    "\n",
    "\n",
    "selected_checkins[:,1] = n+1#+offset1; #n is the indices of the unique values in selected_checkins[:,1]\n",
    "offset2 = max(selected_checkins[:,1]);\n",
    "dumy, dumy, n = np.unique(selected_checkins[:,2],return_index=True,return_inverse=True, axis=0)\n",
    "\n",
    "selected_checkins[:,2] = n+1#+offset2;\n",
    "offset3 = max(selected_checkins[:,2]);\n",
    "dumy, dumy, n = np.unique(selected_checkins[:,3],return_index=True,return_inverse=True, axis=0)\n",
    "selected_checkins[:,3] = n+1#+offset3;\n",
    "\n",
    "num_node_total = max(map(max, selected_checkins)) #max of the entire matrix = 8117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 4)\n",
      "0\n",
      "9\n",
      "0\n",
      "93\n",
      "0\n",
      "162\n",
      "0\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "#verify sequence\n",
    "selected_checkins-=1\n",
    "print(selected_checkins.shape)\n",
    "print(min(selected_checkins[:,0]))\n",
    "print(max(selected_checkins[:,0]))\n",
    "print(min(selected_checkins[:,1]))\n",
    "print(max(selected_checkins[:,1]))\n",
    "print(min(selected_checkins[:,2]))\n",
    "print(max(selected_checkins[:,2]))\n",
    "print(min(selected_checkins[:,3]))\n",
    "print(max(selected_checkins[:,3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_users = max(selected_checkins[:,0])\n",
    "num_of_time = max(selected_checkins[:,1])\n",
    "num_of_venues = max(selected_checkins[:,2])\n",
    "num_of_categories = max(selected_checkins[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "93\n",
      "162\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "print(num_of_users)\n",
    "print(num_of_time)\n",
    "print(num_of_venues)\n",
    "print(num_of_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating training and testing data\n",
    "train_size = int((80/100)*np.size(selected_checkins,0))\n",
    "train_data = selected_checkins[:train_size]\n",
    "nums_type = np.array([num_of_users+1, num_of_time+1, num_of_venues+1, num_of_categories+1])\n",
    "test_data = selected_checkins[train_size:]\n",
    "#data = {'train_data':train_data,'test_data':test_data,'num_types':num_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('lbsndata/train_data.npz', train_data = train_data, nums_type = nums_type)\n",
    "np.savez_compressed('lbsndata/test_data.npz', test_data = test_data, nums_type = nums_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is args\n",
      "Namespace(alpha=1, batch_size=16, data_path='lbsndata', embedding_size=[100, 100, 100, 100], epochs_to_train=5, hidden_size=64, learning_rate=0.01, num_neg_samples=5, options=None, prefix_path='model', save_path='lbsnresult', seed=None)\n",
      "train_data.edge [[  0  22 136  25]\n",
      " [  0  33   2   6]\n",
      " [  0   2 146  49]\n",
      " [  3  14  79  34]\n",
      " [  3  16 125  18]\n",
      " [  3  34 133  55]\n",
      " [  0  48   8   8]\n",
      " [  3  60  69  53]\n",
      " [  3  64 132  13]\n",
      " [  3  70 104  64]\n",
      " [  2  81  73   6]\n",
      " [  0  86  47  42]\n",
      " [  0   8  69  53]\n",
      " [  8  25  87  69]\n",
      " [  1  31 149  18]\n",
      " [  0  32  59  18]\n",
      " [  1  35  70  73]\n",
      " [  0  35   4   8]\n",
      " [  1  40 152  18]\n",
      " [  3  51 108  17]\n",
      " [  0  55  61   0]\n",
      " [  0  60  41  19]\n",
      " [  3  69  10  69]\n",
      " [  9  74 124  72]\n",
      " [  0  23 150  39]\n",
      " [  0  48  21   6]\n",
      " [  0  61 134  12]\n",
      " [  0  62 156  25]\n",
      " [  0  63  60   2]\n",
      " [  0  65 113  14]\n",
      " [  0  66 134  12]\n",
      " [  0  75   3   6]\n",
      " [  0  18  99  58]\n",
      " [  0  22   1   6]\n",
      " [  0  26  75  58]\n",
      " [  0  45   9   5]\n",
      " [  3  46   0   2]\n",
      " [  0  46   2   6]\n",
      " [  0  54  76  17]\n",
      " [  0  76 135  30]\n",
      " [  0  80  31  61]\n",
      " [  0  88  28   7]\n",
      " [  0   1  75  58]\n",
      " [  3   1  62  16]\n",
      " [  3   6 120  37]\n",
      " [  0   7  68   6]\n",
      " [  3   8  12   6]\n",
      " [  3  13  20  21]\n",
      " [  0  24   8   8]\n",
      " [  0  58 112  62]\n",
      " [  0  57  46  64]\n",
      " [  0  21  32  16]\n",
      " [  0  22 141  50]\n",
      " [  0  83  29  32]\n",
      " [  7   6 123  34]\n",
      " [  0  12 145  35]\n",
      " [  7  33  33  20]\n",
      " [  0  37 149  18]\n",
      " [  0  39 149  18]\n",
      " [  0  44  52  17]\n",
      " [  0  59 149  18]\n",
      " [  0  11  84  60]\n",
      " [  0  20   5  10]\n",
      " [  0  26  81   9]\n",
      " [  1  30  34  10]\n",
      " [  0  35 144   4]\n",
      " [  0  36  30  34]\n",
      " [  3  22  18   6]\n",
      " [  3  28  55  25]\n",
      " [  0  53   9   5]\n",
      " [  0  57  90  69]\n",
      " [  1  21  14  66]\n",
      " [  0  26 116  25]\n",
      " [  0  46  34  10]\n",
      " [  0  59 149  18]\n",
      " [  0  86 155   6]\n",
      " [  0  89  80  42]\n",
      " [  2  62  64  49]\n",
      " [  2  63  71   7]\n",
      " [  2  88  58  33]\n",
      " [  0  93  45  11]\n",
      " [  0   1 147  58]\n",
      " [  2  47  38  41]\n",
      " [  2  63  71   7]\n",
      " [  0  13  23  25]\n",
      " [  2  42 102  31]\n",
      " [  0  43 149  18]\n",
      " [  0  46 119  59]\n",
      " [  2  62  85  41]\n",
      " [  0  89  83  65]\n",
      " [  0  90 142  53]\n",
      " [  0  56  56  67]\n",
      " [  2  76  46  64]\n",
      " [  0  48 129  29]\n",
      " [  0  50  22  25]\n",
      " [  2  62 128   7]\n",
      " [  1   7  48  11]\n",
      " [  0  15 149  18]\n",
      " [  2  20  94  17]\n",
      " [  0  20 151  11]\n",
      " [  0  22  67  57]\n",
      " [  0  24  89   6]\n",
      " [  2  33  93  18]\n",
      " [  0  34  43  29]\n",
      " [  2  45  92   1]\n",
      " [  2  46  86   1]\n",
      " [  1  49  74  61]\n",
      " [  1  76  48  11]\n",
      " [  1  92  48  11]\n",
      " [  1  17  40  32]\n",
      " [  1  21  44  41]\n",
      " [  0  13 149  18]\n",
      " [  0  22   8   8]\n",
      " [  0  71 104  64]\n",
      " [  0  85  88  56]\n",
      " [  0  91 130   3]\n",
      " [  8  44 138  34]\n",
      " [  2  45  76  17]\n",
      " [  0  61   8   8]\n",
      " [  0  70  35  26]\n",
      " [  2  19 121  37]\n",
      " [  2  91 158  68]\n",
      " [  0  60  46  64]\n",
      " [  1   6  46  64]\n",
      " [  2   8  46  64]\n",
      " [  0  31  88  56]\n",
      " [  0  39 106  58]\n",
      " [  0  51  75  58]\n",
      " [  0  66 100  11]\n",
      " [  0   9  18   6]\n",
      " [  0  12  46  64]\n",
      " [  0  75  46  64]\n",
      " [  0   0 157  58]\n",
      " [  0  20 115  45]\n",
      " [  0  26  75  58]\n",
      " [  0  44  63  44]\n",
      " [  0  51  75  58]\n",
      " [  0  55  56  67]\n",
      " [  0  58 159  70]\n",
      " [  2  76 122  22]\n",
      " [  0  50  46  64]\n",
      " [  3  77 114   4]\n",
      " [  3   8 160  31]\n",
      " [  0  61  46  64]\n",
      " [  0  73 149  18]\n",
      " [  0   0 157  58]\n",
      " [  0  20  95  46]\n",
      " [  0  25 157  58]\n",
      " [  0  47  68   6]\n",
      " [  2  55 118  27]\n",
      " [  0  55 137   4]\n",
      " [  2  68  53  48]\n",
      " [  2  70  39  43]\n",
      " [  0   2 137   4]\n",
      " [  0  29 137   4]\n",
      " [  2  42  98  71]\n",
      " [  5  44 140  34]\n",
      " [  5  54  16  73]\n",
      " [  2  55  78  49]\n",
      " [  5  67  97  38]\n",
      " [  5  85  82  42]\n",
      " [  0  51  75  58]\n",
      " [  2  56  26  58]\n",
      " [  2  82 117  63]\n",
      " [  2  82  91  62]\n",
      " [  0  87 155   6]\n",
      " [  0  35   7   8]\n",
      " [  0  39 131  47]\n",
      " [  0  45   5  10]\n",
      " [  0  20  34  10]\n",
      " [  0  23  95  46]\n",
      " [  0  64  88  56]\n",
      " [  0  64   4   8]\n",
      " [  2   3  11  22]\n",
      " [  4   2  36  34]\n",
      " [  4   5  77  15]\n",
      " [  4  20 111  72]\n",
      " [  4  27  51  24]\n",
      " [  4  34  54  51]\n",
      " [  4  35 126  67]\n",
      " [  2  87  46  64]\n",
      " [  0  52 101  69]\n",
      " [  0  75  27   6]\n",
      " [  0  79 128   7]\n",
      " [  2  85 105   6]\n",
      " [  4  88  46  64]\n",
      " [  0  30 137   4]\n",
      " [  0  77  13  52]\n",
      " [  0  89 143   4]\n",
      " [  2  32 149  18]\n",
      " [  0  33 152  18]\n",
      " [  0  61 149  18]\n",
      " [  0  61 110   9]\n",
      " [  0  72   6   3]\n",
      " [  0  84 130   3]\n",
      " [  2  64 107  28]]\n",
      "train_data.nums_type [ 10  94 163  74]\n",
      "9 , 10\n",
      "93 , 94\n",
      "160 , 163\n",
      "73 , 74\n",
      "WARNING:tensorflow:From /home/disha/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_0 (InputLayer)            (None, 331)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 247)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 178)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 267)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encode_0 (Dense)                (None, 100)          33200       input_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encode_1 (Dense)                (None, 100)          24800       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encode_2 (Dense)                (None, 100)          17900       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encode_3 (Dense)                (None, 100)          26800       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 400)          0           encode_0[0][0]                   \n",
      "                                                                 encode_1[0][0]                   \n",
      "                                                                 encode_2[0][0]                   \n",
      "                                                                 encode_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "full_connected_layer (Dense)    (None, 64)           25664       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decode_0 (Dense)                (None, 331)          33431       encode_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decode_1 (Dense)                (None, 247)          24947       encode_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decode_2 (Dense)                (None, 178)          17978       encode_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decode_3 (Dense)                (None, 267)          26967       encode_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classify_layer (Dense)          (None, 1)            65          full_connected_layer[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 231,752\n",
      "Trainable params: 231,752\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/disha/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 0.8486 - decode_0_loss: 0.0104 - decode_1_loss: 0.0019 - decode_2_loss: 0.0023 - decode_3_loss: 0.0032 - classify_layer_loss: 0.8308 - decode_0_mean_squared_error: 0.4192 - decode_1_mean_squared_error: 0.3734 - decode_2_mean_squared_error: 0.3198 - decode_3_mean_squared_error: 0.3709 - classify_layer_acc: 0.7532 - val_loss: 0.4281 - val_decode_0_loss: 0.0013 - val_decode_1_loss: 5.3789e-04 - val_decode_2_loss: 4.4519e-04 - val_decode_3_loss: 7.3765e-04 - val_classify_layer_loss: 0.4250 - val_decode_0_mean_squared_error: 0.4551 - val_decode_1_mean_squared_error: 0.4213 - val_decode_2_mean_squared_error: 0.3824 - val_decode_3_mean_squared_error: 0.4454 - val_classify_layer_acc: 0.8333\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.4293 - decode_0_loss: 9.5996e-04 - decode_1_loss: 4.6193e-04 - decode_2_loss: 8.3057e-04 - decode_3_loss: 7.8394e-04 - classify_layer_loss: 0.4263 - decode_0_mean_squared_error: 0.4678 - decode_1_mean_squared_error: 0.5072 - decode_2_mean_squared_error: 0.4114 - decode_3_mean_squared_error: 0.4802 - classify_layer_acc: 0.8341 - val_loss: 0.4496 - val_decode_0_loss: 3.6915e-04 - val_decode_1_loss: 2.4442e-04 - val_decode_2_loss: 4.5273e-04 - val_decode_3_loss: 4.5747e-04 - val_classify_layer_loss: 0.4481 - val_decode_0_mean_squared_error: 0.4438 - val_decode_1_mean_squared_error: 0.4932 - val_decode_2_mean_squared_error: 0.4485 - val_decode_3_mean_squared_error: 0.4657 - val_classify_layer_acc: 0.8333\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.4296 - decode_0_loss: 4.0239e-04 - decode_1_loss: 2.5389e-04 - decode_2_loss: 4.1466e-04 - decode_3_loss: 4.4232e-04 - classify_layer_loss: 0.4281 - decode_0_mean_squared_error: 0.4712 - decode_1_mean_squared_error: 0.5565 - decode_2_mean_squared_error: 0.4673 - decode_3_mean_squared_error: 0.5380 - classify_layer_acc: 0.8349 - val_loss: 0.4165 - val_decode_0_loss: 3.2522e-04 - val_decode_1_loss: 1.5023e-04 - val_decode_2_loss: 1.3893e-04 - val_decode_3_loss: 3.1764e-04 - val_classify_layer_loss: 0.4155 - val_decode_0_mean_squared_error: 0.4857 - val_decode_1_mean_squared_error: 0.5010 - val_decode_2_mean_squared_error: 0.4327 - val_decode_3_mean_squared_error: 0.5574 - val_classify_layer_acc: 0.8333\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4296 - decode_0_loss: 3.6541e-04 - decode_1_loss: 1.5783e-04 - decode_2_loss: 2.3521e-04 - decode_3_loss: 2.3982e-04 - classify_layer_loss: 0.4286 - decode_0_mean_squared_error: 0.4877 - decode_1_mean_squared_error: 0.5749 - decode_2_mean_squared_error: 0.5139 - decode_3_mean_squared_error: 0.5855 - classify_layer_acc: 0.8349 - val_loss: 0.4173 - val_decode_0_loss: 3.1603e-04 - val_decode_1_loss: 9.4595e-05 - val_decode_2_loss: 1.5347e-04 - val_decode_3_loss: 2.0854e-04 - val_classify_layer_loss: 0.4165 - val_decode_0_mean_squared_error: 0.4841 - val_decode_1_mean_squared_error: 0.5188 - val_decode_2_mean_squared_error: 0.5432 - val_decode_3_mean_squared_error: 0.6118 - val_classify_layer_acc: 0.8333\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4221 - decode_0_loss: 2.5064e-04 - decode_1_loss: 1.0353e-04 - decode_2_loss: 1.5063e-04 - decode_3_loss: 1.7493e-04 - classify_layer_loss: 0.4214 - decode_0_mean_squared_error: 0.4780 - decode_1_mean_squared_error: 0.5945 - decode_2_mean_squared_error: 0.5521 - decode_3_mean_squared_error: 0.6173 - classify_layer_acc: 0.8325 - val_loss: 0.4708 - val_decode_0_loss: 3.6373e-04 - val_decode_1_loss: 8.6225e-05 - val_decode_2_loss: 5.7561e-05 - val_decode_3_loss: 2.6974e-04 - val_classify_layer_loss: 0.4700 - val_decode_0_mean_squared_error: 0.4524 - val_decode_1_mean_squared_error: 0.5804 - val_decode_2_mean_squared_error: 0.5128 - val_decode_3_mean_squared_error: 0.6145 - val_classify_layer_acc: 0.8333\n",
      "time,  4.694572687149048\n"
     ]
    }
   ],
   "source": [
    "#selected_checkins format -\n",
    "#selected_checkins (4 columns): user_index, time (hour in a week), venue_index, venue_category_index\n",
    "#feeding it as it is to DHNE\n",
    "\n",
    "%run hypergraph_embedding.py --data_path lbsndata --save_path lbsnresult -s 100 100 100 100 -e 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "embed[0].shape (10, 100)\n",
      "embed[1].shape (94, 100)\n",
      "embed[2].shape (163, 100)\n",
      "embed[3].shape (74, 100)\n"
     ]
    }
   ],
   "source": [
    "#embeddings are stored in lbsnresult/model_(no.ofemneddings)/embeddings.npy\n",
    "#corresponding model stored in lbsnresult/model_(no.ofemneddings)/model.h5\n",
    "\n",
    "embed = np.load('lbsnresult/model_100/embeddings.npy')\n",
    "print(embed.shape)\n",
    "print('embed[0].shape',embed[0].shape)\n",
    "print('embed[1].shape',embed[1].shape)\n",
    "print('embed[2].shape',embed[2].shape)\n",
    "print('embed[3].shape',embed[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is count  3\n",
      "this is count fraction  0.06\n",
      "time lapsed  0.8240852355957031\n"
     ]
    }
   ],
   "source": [
    "#location prediction on the learnt embeddings\n",
    "#selected_checkins (4 columns): user_index, time (hour in a week), venue_index, venue_category_index\n",
    "import time as tm\n",
    "from scipy.spatial import distance\n",
    "\n",
    "count = 0\n",
    "\n",
    "start = tm.time()\n",
    "for d in range(test_data.shape[0]):\n",
    "    test = test_data[d]\n",
    "    user = test[0]\n",
    "    time = test[1]\n",
    "    dist = []\n",
    "    \n",
    "    for i in range(min(test_data[:,2]),max(test_data[:,2])+1):\n",
    "        summ = (1 - distance.cosine(embed[0][user],embed[2][i]))+(1 - distance.cosine(embed[1][time],embed[2][i]))\n",
    "        dist.append((abs(summ),i))\n",
    "        \n",
    "    dist = sorted(dist, key=lambda student: student[0])\n",
    "    if test[2] in (np.array(dist[0:20])[:,1]):\n",
    "        count+=1\n",
    "        \n",
    "ending = tm.time()\n",
    "\n",
    "print(\"this is count \",count)\n",
    "print(\"this is count fraction \",count/test_data.shape[0])\n",
    "print(\"time lapsed \",ending-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
